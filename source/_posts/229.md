### 原文^[https://www.humanityplus.org/the-transhumanist-declaration]
The Transhumanist Declaration was originally crafted in 1998 by an international group of authors: Doug Baily, Anders Sandberg, Gustavo Alves, Max More, Holger Wagner, Natasha Vita-More, Eugene Leitl, Bernie Staring, David Pearce, Bill Fantegrossi, den Otter, Ralf Fletcher, Tom Morrow, Alexander Chislenko, Lee Daniel Crocker, Darren Reynolds, Keith Elis, Thom Quinn, Mikhail Sverdlov, Arjen Kamphuis, Shane Spaulding, and Nick Bostrom. This Transhumanist Declaration has been modified over the years by several authors and organizations. It was adopted by the Humanity+ Board in March, 2009.
- 1. Humanity stands to be profoundly affected by science and technology in the future. We envision the possibility of broadening human potential by overcoming aging, cognitive shortcomings, involuntary suffering, and our confinement to planet Earth.
- 2. We believe that humanity’s potential is still mostly unrealized. There are possible scenarios that lead to wonderful and exceedingly worthwhile enhanced human conditions.
- 3. We recognize that humanity faces serious risks, especially from the misuse of new technologies. There are possible realistic scenarios that lead to the loss of most, or even all, of what we hold valuable. Some of these scenarios are drastic, others are subtle. Although all progress is change, not all change is progress.
- 4. Research effort needs to be invested into understanding these prospects. We need to carefully deliberate how best to reduce risks and expedite beneficial applications. We also need forums where people can constructively discuss what should be done, and a social order where responsible decisions can be implemented.
- 5. Reduction of existential risks, and development of means for the preservation of life and health, the alleviation of grave suffering, and the improvement of human foresight and wisdom should be pursued as urgent priorities, and heavily funded.
- 6. Policy making ought to be guided by responsible and inclusive moral vision, taking seriously both opportunities and risks, respecting autonomy and individual rights, and showing solidarity with and concern for the interests and dignity of all people around the globe. We must also consider our moral responsibilities towards generations that will exist in the future.
- 7. We advocate the well-being of all sentience, including humans, non-human animals, and any future artificial intellects, modified life forms, or other intelligences to which technological and scientific advance may give rise.
- 8. We favour allowing individuals wide personal choice over how they enable their lives. This includes use of techniques that may be developed to assist memory, concentration, and mental energy; life extension therapies; reproductive choice technologies; cryonics procedures; and many other possible human modification and enhancement technologies.
### 中文翻译
（By Google Translate）
《超人类主义宣言》最初由一群国际作家于1998年起草：Doug Baily、Anders Sandberg、Gustavo Alves、Max More、Holger Wagner、Natasha Vita-More、Eugene Leitl、Bernie Staring、David Pearce、Bill Fantegrossi、den Otter、Ralf Fletcher、Tom Morrow、Alexander Chislenko、Lee Daniel Crocker、Darren Reynolds、Keith Elis、Thom Quinn、Mikhail Sverdlov、Arjen Kamphuis、Shane Spaulding 和 Nick Bostrom。多年来，这份《超人类主义宣言》已被多位作家和组织修改。2009年3月，Humanity+董事会通过了该宣言。
- 1. 未来，人类将受到科学和技术的深刻影响。我们设想，通过克服衰老、认知缺陷、非自愿的痛苦以及地球的局限，人类的潜力将得到拓展。
- 2. 我们相信人类的潜力大部分仍未实现。可能出现一些情景，带来美妙而极其有价值的人类状况改善。
- 3. 我们认识到人类面临严重风险，尤其是滥用新技术的风险。可能出现一些现实情景，导致我们失去大部分甚至所有宝贵的东西。其中一些情景非常剧烈，另一些则比较微妙。虽然所有进步都是变化，但并非所有变化都是进步。
- 4. 需要投入研究精力来了解这些前景。我们需要仔细考虑如何最好地降低风险并加快有益的应用。我们还需要论坛，让人们可以建设性地讨论应该做什么，以及可以实施负责任决策的社会秩序。
- 5. 应将减少生存风险、开发保护生命和健康的手段、减轻严重痛苦以及提高人类的远见和智慧作为紧急优先事项，并投入大量资金。
- 6. 政策制定应以负责任和包容的道德观为指导，认真对待机遇和风险，尊重自主权和个人权利，团结并关心全球所有人的利益和尊严。我们还必须考虑我们对未来几代人的道德责任。
- 7. 我们提倡所有有知觉的生物的福祉，包括人类、非人类动物以及任何未来的人工智能、改良生命形式或技术和科学进步可能产生的其他智能。
- 8. 我们赞成允许个人在如何实现自己的生活方面拥有广泛的个人选择。这包括使用可能开发的技术来辅助记忆、注意力和精神能量；延长寿命的疗法；生殖选择技术；低温程序；以及许多其他可能的人类改造和增强技术。
